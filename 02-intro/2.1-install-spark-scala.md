<link rel='stylesheet' href='../assets/css/main.css'/>

[<< back to main index](../README.md)

# Lab 2.1: Up and Running With Spark

### Overview
We will be running Spark in a single-node mode.

### Depends On
None

### Run time
20 mins

## STEP 0: To Instructor
Please go through this lab on 'screen' first.

## STEP 1: Log in to your Spark node
The instructor will provide details


## STEP 2: (Optional / Reference Only) Installing Spark

Note, **Spark is already installed** in the latest docker image.  

**You can skip this step**

The following is provided as a reference.

(copy paste the following commands on terminal,  do not include $ in your commands)

```bash
    $   cd ~/apps
    $   rm -rf  spark   # cleanup existing spark installation (if any)
    $   wget  https://elephantscale-public.s3.amazonaws.com/downloads/spark-2.4.3-bin-hadoop2.7.tgz
    $   tar xvf   spark-2.4.3-bin-hadoop2.7.tgz
    $   mv  spark-2.4.3-bin-hadoop2.7    spark
```

Now we have spark installed in  `~/spark`  directory


## STEP 3: Running Spark

```bash
    $   ~/apps/spark/sbin/start-all.sh
```

Verify Spark is running by 'jps' command
```bash
    $  jps
```

Your output may look like this..
```console
  30624 Jps
  30431 Master
  30565 Worker
```
you will see **Master** and **Worker**  processes running.
(you probably will get different values for process ids - first column )

Spark UI will be at port 8080 of the host.
In the browser go to
  http://your_spark_host_address:8080
(be sure to use the 'public' ip address)

Bingo!  Now we have spark running.


## STEP 4: Exploring Spark UI
You will see a similar screen shot like this

<img src="../assets/images/1a.png" style="border: 5px solid grey ; max-width:100%;" />

To explore:
* Is Master and Worker running on the same node?

* Inspect memory & CPU available for Spark worker

* Note the Spark master URI; it will be something like
      spark://host_name:7077
    We will need this for later labs.


## STEP 5: Download Spark labs & Data

### Get Labs

Instructor will distribute the lab bundle

### Data

Download the dataset
```bash
cd
git clone https://github.com/elephantscale/datasets.git
mv datasets/ data
sudo mv   data/ /data
```

**Downloading the dataset to your own machine**  
Please see [README.md data section](../README-scala.md#data)

## Optional: Spark Sandbox

To run Spark on your laptop, we recommend the sandbox.  This Sandbox can run on Mac / Windows / Linux.

Get it [here](https://hub.docker.com/r/elephantscale/es-training)

